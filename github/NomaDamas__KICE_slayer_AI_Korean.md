---
Language: Python  
tags:  
 - AI 벤치마크  
 - 수능 국어  
 - LLM 평가  
aliases:  
 - AI수능국어  
 - 수능AI평가  
 - 한국어LLM성능분석  
url: https://github.com/PCEO-AI-CLUB/KICE_slayer_AI_Korean  
---  
이 프로젝트는 2015~2024학년도 수능 국어 문제를 활용해 다양한 대규모 언어 모델(LLM)의 성능을 체계적으로 벤치마킹한 연구입니다. GPT-4, GPT-3.5-16K, Synatra-7B 모델을 대상으로 9가지 프롬프트 기법을 적용해 10개년도 수능 문제를 평가하였으며, 모델별 특징(예: 영어 프롬프트 선호, 한국어 파인튜닝 한계)과 프롬프트 최적화 전략을 분석했습니다. 데이터화, 프롬프트 설계, 벤치마킹 방법론을 공개하여 AI 기반 수능 평가의 재현성과 확장성을 지원합니다.  

### 주요 결과  
- **GPT-4**: 영어 프롬프트에서 최고 성능(72.67점) 달성  
- **GPT-3.5-16K**: 프롬프트 엔지니어링으로 최대 35점 향상  
- **Synatra-7B**: 영어 프롬프트에서만 제한적 성능(24.2점)  
- **프롬프트 순위**: 형식 지정 > zero-shot-CoT-영어 > zero-shot-CoT 순으로 효과적  
- **모델 간 격차**: GPT-4와 GPT-3.5-16K 간 평균 33점 차이, Synatra-7B는 찍기 수준(15.6점)  

AutoRAG 도구로 데이터셋을 구성하고, 프롬프트별 결과를 공개해 AI 독해력 연구의 베이스라인으로 활용될 수 있도록 설계되었습니다.