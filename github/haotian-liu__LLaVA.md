---
Language: Python  
tags:  
 - Vision-Language Model  
 - GPT-4 수준  
 - 멀티모달 AI  
 - 이미지 분석  
 - 오픈소스 LMM  
aliases:  
 - LLaVA  
 - LLaVA-NeXT  
 - LLaVA-1.5  
 - LLaVA-Med  
 - 멀티모달 언어모델  
url: https://github.com/haotian-liu/LLaVA  
---  
LLaVA는 시각-언어 통합 모델로, GPT-4 수준의 멀티모달 능력을 목표로 합니다. 이미지 이해와 언어 생성을 결합해 다양한 시각-언어 작업(이미지 설명, 질문 응답 등)을 수행하며, 지속적인 개선을 통해 LLaVA-NeXT, LLaVA-1.5 등 강력한 버전을 출시했습니다. 오픈소스 생태계를 기반으로 연구 및 상용화 가능한 멀티모달 AI 솔루션을 제공합니다.