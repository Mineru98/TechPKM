---
Language: Python
tags:
 - autonomous-agent
 - llama-model
 - llama.cpp
 - AI-실험
 - 로컬-LLM
aliases:
 - Auto-Llama-cpp
 - 자율-LLaMA-실험
 - 로컬-LLM-에이전트
url: https://github.com/rhohndorf/Auto-Llama-cpp
---
Auto-Llama-cpp는 Auto-GPT를 포크하여 로컬에서 실행되는 Llama 모델(llama.cpp 기반)을 지원하는 자율 에이전트 실험 프로젝트입니다. 현재 개념 검증 단계로, 느린 추론 속도와 작은 컨텍스트 윈도우 한계로 인해 제한적이지만, 특정 모델(예: Vicuna-13B)에서는 JSON 형식의 유의미한 답변을 생성하기도 합니다. 주요 지원 모델은 LLaMA, Alpaca, GPT4All, Vicuna 등이며, GPU 지원 추가 및 프롬프트 개선 등의 계획이 있습니다.