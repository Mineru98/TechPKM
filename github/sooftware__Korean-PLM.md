---
Language: Markdown
tags:
 - 한국어 모델
 - 사전학습 모델
 - NLP
 - 트랜스포머
 - BERT/GPT/T5
aliases:
 - 한국어 PLM
 - Korean PLM
 - 한국어 사전학습 모델 목록
url: https://github.com/Korean-PLM/Korean-PLM
---
한국어 자연어 처리(NLP)를 위한 공개 사전학습 모델 목록을 체계적으로 정리한 프로젝트입니다. BERT 계열 인코더 모델, GPT 계열 디코더 모델, Seq2seq 계열 인코더-디코더 모델로 분류하여 각 모델의 크기, 용도, 링크 정보를 제공합니다. 한국어 텍스트 처리 작업에 최적화된 다양한 모델들을 한곳에서 확인할 수 있습니다.  

이 문서는 한국어 기반 트랜스포머 모델들의 기술적 특성을 비교 분석하거나 적합한 모델을 선택할 때 참고할 수 있는 메타정보를 제공합니다.