---
Language: Python  
tags:  
 - Instruction Tuning  
 - 언어 모델  
 - DPO  
 - RLHF  
 - 오픈소스  
aliases:  
 - TÜLU  
 - 오픈 인스트럭트  
 - Tulu 3  
url: https://github.com/allenai/open-instruct  
---  
이 프로젝트는 공개 데이터셋을 활용해 사전 학습된 언어 모델을 인스트럭션 튜닝 및 포스트트레이닝하기 위한 오픈소스 노력을 제공합니다. TÜLU 3를 포함한 최신 기술을 적용하여 Llama-3.1 및 OLMo-2 모델 기반의 다양한 체크포인트와 학습 코드를 공개하며, DPO(직접 선호도 최적화), PPO(강화 학습), RLVR(검증 가능한 보상 기반 강화 학습) 기법을 지원합니다. HuggingFace에서 제공하는 SFT, DPO, 최종 모델 및 보상 모델을 활용해 효율적인 인스트럭션 팔로잉 성능을 구현할 수 있습니다.