---
Language: Python  
tags:  
 - 언어모델정렬  
 - DPO  
 - ORPO  
 - ReinforcementLearning  
 - HuggingFace  
aliases:  
 - AlignmentHandbook  
 - 언어모델정렬가이드  
 - DPO튜닝레시피  
 - ORPO튜닝레시피  
url: https://github.com/huggingface/alignment-handbook  
---
이 프로젝트는 언어 모델을 인간 및 AI 선호도에 맞춰 정렬하기 위한 견고한 훈련 레시피를 제공합니다. 사전 훈련된 언어 모델을 계속 훈련시키고, 지도 미세 조정(SFT), 직접 선호 최적화(DPO), 확률비 선호 최적화(ORPO) 등을 통해 모델 성능을 향상시키는 방법을 다룹니다. Hugging Face에서 제공하는 다양한 레시피와 스크립트를 활용해 Zephyr, SmolLM 등의 모델 재현 및 맞춤형 채팅 모델 훈련이 가능합니다. 주로 소규모 언어 모델부터 대규모 모델까지 적용 가능한 실용적인 가이드를 제공합니다.