---
Language: Python  
tags:  
 - 한국어 NLP  
 - ELECTRA 모델  
 - 트랜스포머  
 - 사전학습 언어 모델  
 - KoELECTRA  
aliases:  
 - KoELECTRA 모델  
 - 한국어 ELECTRA  
 - KoELECTRA 베이스/스몰  
url: https://github.com/monologg/KoELECTRA  
---
KoELECTRA는 한국어 텍스트를 위한 ELECTRA 기반 사전학습 언어 모델입니다. 34GB의 한국어 말뭉치로 학습되었으며, `KoELECTRA-Base`와 `KoELECTRA-Small` 두 가지 버전을 제공합니다. Wordpiece 토크나이저를 사용하며 Huggingface Transformers 라이브러리와 호환되어 모델 다운로드 없이 즉시 활용 가능합니다. 다양한 한국어 NLP 태스크에서 높은 성능을 입증했으며, TensorFlow/PyTorch에서 모두 사용할 수 있습니다.